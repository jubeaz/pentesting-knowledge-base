\section{http}

\subsection{http.server}

\subsubsection{GET/POST server}

\begin{verbatim}
#!/usr/bin/env python3
"""
Very simple HTTP server in python for logging requests
Usage::
    ./server.py [<port>]
"""
from http.server import BaseHTTPRequestHandler, HTTPServer
import logging

class S(BaseHTTPRequestHandler):
    def _set_response(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/html')
        self.end_headers()

    def do_GET(self):
        log=f'''
GET {str(self.path)} {str(self.request_version)}
{str(self.headers)}'''
        logging.info(log)
        self._set_response()
        self.wfile.write("GET request for {}".format(self.path).encode('utf-8'))

    def do_POST(self):
        # Get data size
        content_length = int(self.headers['Content-Length'])
        # Get data
        post_data = self.rfile.read(content_length)
        log=f'''
POST {str(self.path)} {str(self.request_version)}
{str(self.headers)}{post_data.decode('utf-8')}
'''
        logging.info(log)
        self._set_response()
        self.wfile.write("POST request for {}".format(self.path).encode('utf-8'))

def run(server_class=HTTPServer, handler_class=S, port=8080):
    logging.basicConfig(level=logging.INFO)
    server_address = ('', port)
    httpd = server_class(server_address, handler_class)
    logging.info('Starting httpd...\n')
    try:
        httpd.serve_forever()
    except KeyboardInterrupt:
        pass
    httpd.server_close()
    logging.info('Stopping httpd...\n')

if __name__ == '__main__':
    from sys import argv

    if len(argv) == 2:
        run(port=int(argv[1]))
    else:
        run()

\end{verbatim}


\subsubsection{Add redirection}
\begin{verbatim}
    def _set_response(self):
        self.send_response(301)
        self.send_header('Location',f'{redirect_url}')
        self.end_headers()
\end{verbatim}

\subsection{Requests}


\url{https://requests.readthedocs.io/en/latest/}
\subsubsection{Simple Simple}
\begin{verbatim}
proxies = {
   'http': 'http://proxy.example.com:8080',
   'https': 'http://secureproxy.example.com:8090',
}

response = requests.post(url, proxies=proxies)
\end{verbatim}


\subsubsection{Session proxy}
You may also find yourself wanting to scrape from websites that utilize
sessions, in this case, you would have to create a session object. You can do
this by first creating a \verb+session+ variable and setting it to the requests
\verb+Session()+ method. Then similar to before, you would send your session
proxies through the requests method, but this time only passing in the
\verb+url+ as the argument.

\begin{verbatim}
session = requests.Session()

session.proxies = {
   'http': 'http://10.10.10.10:8000',
   'https': 'http://10.10.10.10:8000',
}

response = session.get(url)
\end{verbatim}

\subsubsection{file upload}
\begin{verbatim}
    url='http://images.late.htb/scanner'
    file ={'file': ('paylaod.png', open('test.png', 'rb'),'image/png')}
    r = requests.post(url, files=file, proxies=proxies)
    print(r.text)

\end{verbatim}

\subsubsection{logging}
{\bf Solution 1}
\begin{verbatim}
import requests
import http
import logging

# Set up logging to a file
logging.basicConfig(filename="app.log", level=logging.DEBUG)
logger = logging.getLogger(__name__)
http.client.HTTPConnection.debuglevel = 1

# Monkey patch the print() function and redirect it to a logger.debug() call
def print_to_log(*args):
    logger.debug(" ".join(args))
http.client.print = print_to_log

# Test HTTP GET and POST
url = "http://localhost:5000/test"

logger.info("Sending HTTP GET")
resp = requests.get(url)

logger.info("Sending HTTP POST")
resp = requests.post(url, data='My Test Data')
\end{verbatim}

{\bf solution 2} 
\begin{verbatim}
import logging
import contextlib
try:
    from http.client import HTTPConnection # py3
except ImportError:
    from httplib import HTTPConnection # py2

def debug_requests_on():
    '''Switches on logging of the requests module.'''
    HTTPConnection.debuglevel = 1

    logging.basicConfig()
    logging.getLogger().setLevel(logging.DEBUG)
    requests_log = logging.getLogger("requests.packages.urllib3")
    requests_log.setLevel(logging.DEBUG)
    requests_log.propagate = True

def debug_requests_off():
    '''Switches off logging of the requests module, might be some side-effects'''
    HTTPConnection.debuglevel = 0

    root_logger = logging.getLogger()
    root_logger.setLevel(logging.WARNING)
    root_logger.handlers = []
    requests_log = logging.getLogger("requests.packages.urllib3")
    requests_log.setLevel(logging.WARNING)
    requests_log.propagate = False

@contextlib.contextmanager
def debug_requests():
    '''Use with 'with'!'''
    debug_requests_on()
    yield
    debug_requests_off()
\end{verbatim}

call:
\begin{verbatim}
>>> requests.get('http://httpbin.org/')
<Response [200]>

>>> debug_requests_on()
>>> requests.get('http://httpbin.org/')
INFO:requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): httpbin.org
DEBUG:requests.packages.urllib3.connectionpool:"GET / HTTP/1.1" 200 12150
send: 'GET / HTTP/1.1\r\nHost: httpbin.org\r\nConnection: keep-alive\r\nAccept-
Encoding: gzip, deflate\r\nAccept: */*\r\nUser-Agent: python-requests/2.11.1\r\n\r\n'
reply: 'HTTP/1.1 200 OK\r\n'
header: Server: nginx
...
<Response [200]>

>>> debug_requests_off()
>>> requests.get('http://httpbin.org/')
<Response [200]>

>>> with debug_requests():
...     requests.get('http://httpbin.org/')
INFO:requests.packages.urllib3.connectionpool:Starting new HTTP connection (1): httpbin.org
...
<Response [200]>
\end{verbatim}


\subsubsection{example}
\begin{verbatim}
import requests
import time
url = "http://{}/login.php".format(ip)
# rate limit blocks for 30 seconds
lock_time = 30
# message that alert us we hit rate limit
lock_message = "Too many login failure"
# read user and password
for username in ["support.cn", "support.gr", "support.it",  "support.us"]:
    with open(userpass_file, "r") as fh:
        for fline in fh:
            if fline.startswith("#"):
                continue
            password = fline.rstrip()
            data = {
                "userid": username,
                "passwd": password,
                "submit": "submit"
            }
    
            #print(" test {} ".format(password))
            # do the request
            res = requests.post(url, headers=headers, data=data)
            #print(res.text)
    
            # handle generic credential error
            if "Invalid credentials" in res.text:
                print("[-] Invalid credentials: userid:{} passwd:{}".format(user
name, password))
            elif lock_message in res.text:
                print("[-] Hit rate limit, sleeping 30")
                # do the actual sleep plus 0.5 to be sure
                time.sleep(lock_time+0.5)
            else:
                print("[+++++++++++] Valid credentials: userid:{} passwd:{}".for
mat(username, password))
                exit()

\end{verbatim}

\subsection{URL Encoding query strings or form parameters}
\url{https://www.urlencoder.io/python/}

\begin{verbatim}
>>> import urllib.parse
>>> query = 'Hellö Wörld@Python'
>>> urllib.parse.quote(query)
'Hell%C3%B6%20W%C3%B6rld%40Python'


urllib.parse.quote('/', safe='')
'%2F'

# encode + - 
>>> import urllib.parse
>>> query = 'Hellö Wörld@Python'
>>> urllib.parse.quote_plus(query)
'Hell%C3%B6+W%C3%B6rld%40Python'


>>> import urllib.parse
>>> params = {'q': 'Python URL encoding', 'as_sitesearch': 'www.urlencoder.io'}
>>> urllib.parse.urlencode(params)
'q=Python+URL+encoding&as_sitesearch=www.urlencoder.io'

# If you want the urlencode() function to use the quote() function for encoding parameters
urllib.parse.urlencode(params, quote_via=urllib.parse.quote)


>>> import urllib.parse
>>> params = {'name': 'Rajeev Singh', 'phone': ['+919999999999', '+628888888888']}
>>> urllib.parse.urlencode(params, doseq=True)
'name=Rajeev+Singh&phone=%2B919999999999&phone=%2B628888888888'
\end{verbatim}

\subsection{Beautiful Soup}

\href{https://beautiful-soup-4.readthedocs.io/en/latest/}{Beautiful Soup}is a
Python library for pulling data out of HTML and XML files. It works with your
favorite parser to provide idiomatic ways of navigating, searching, and
modifying the parse tree. 
