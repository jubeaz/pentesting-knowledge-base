
\section{Components of a Report}
As mentioned previously, the report is the main deliverable that a client is
paying for when they contract your firm to perform a penetration test. The
report is our chance to show off our work during the assessment and provide the
client with as much value as possible. Ideally, the report will be free of
extraneous data and information that "clutter" up the report or distract from
the issues we are trying to convey of the overall picture of their security
posture we are trying to paint. Everything in the report should have a reason
for being there, and we don't want to overwhelm the reader (for example, don't
paste in 50+ pages of console output!). In this section, we'll cover the key
elements of a report and how we can best structure it to show off our work and
help our clients prioritize remediation.

\subsection{Prioritizing Our Efforts}

During an assessment, especially large ones, we'll be faced with a lot of
"noise" that we need to filter out to best focus our efforts and prioritize
findings. As testers, we are required to disclose everything we find, but when
there is a ton of information coming at us through scans and enumeration, it is
easy to get lost or focus on the wrong things and waste time and potentially
miss high-impact issues. This is why it is essential that we understand the
output that our tools produce, have repeatable steps (such as scripts or other
tools) to sift through all of this data, process it, and remove false positives
or informational issues that could distract us from the goal of the assessment.
Experience and a repeatable process are key so that we can sift through all of
our data and focus our efforts on high-impact findings such as remote code
execution (RCE) flaws or others that may lead to sensitive data disclosure. It
is worth it (and our duty) to report informational findings, but instead of
spending the majority of our time validating these minor, non-exploitable
issues, you may want to consider consolidating some of them into categories
that show the client you were aware that the issues existed, but you were
unable to exploit them in any meaningful way (e.g., 35 different variations of
problems with SSL/TLS, a ton of DoS vulnerabilities in an EOL version of PHP,
etc.).

When starting in penetration testing, it can be difficult to know what to
prioritize, and we may fall down rabbit holes trying to exploit a flaw that
doesn't exist or getting a broken PoC exploit to work. Time and experience help
here, but we should also lean on senior team members and mentors to help.
Something that you may waste half a day on could be something that they have
seen many times and could tell you quickly whether it is a false positive or
worth running down. Even if they can't give you a really quick black and white
answer, they can at least point you in a direction that saves you several
hours. Surround yourself with people you're comfortable with asking for help
that won't make you feel like an idiot if you don't know all the answers.

\subsection{Writing an Attack Chain}

The attack chain is our chance to show off the cool exploitation chain we took
to gain a foothold, move laterally, and compromise the domain. It can be a
helpful mechanism to help the reader connect the dots when multiple findings
are used in conjunction with each other and gain a better understanding of why
certain findings are given the severity rating that they are assigned. For
example, a particular finding on its own may be medium-risk but, combined with
one or two other issues, could elevate it to high-risk, and this section is our
chance to demonstrate that. A common example is using Responder to intercept
NBT-NS/LLMNR traffic and relaying it to hosts where SMB signing is not present.
It can get really interesting if some findings can be incorporated that might
otherwise seem inconsequential, like using an information disclosure of some
sort to help guide you through an LFI to read an interesting configuration
file, log in to an external-facing application, and leverage functionality to
gain remote code execution and a foothold inside the internal network.

There are multiple ways to present this, and your style may differ but let's
walk through an example. We will start with a summary of the attack chain and
then walk through each step along with supporting command output and
screenshots to show the attack chain as clearly as possible. A bonus here is
that we can re-use this as evidence for our individual findings so we don't
have to format things twice and can copy/paste them into the relevant finding.

\subsubsection{Sample Attack Chain - INLANEFREIGHT.LOCAL Internal Penetration
Test}

During the Internal Penetration Test performed against Inlanefreight, the
tester gained a foothold in the internal network, moved laterally, and
ultimately compromised the INLANEFREIGHT.LOCAL Active Directory domain. The
below walkthrough illustrates the steps taken to go from an unauthenticated
anonymous user in the internal network to Domain Admin level access. The intent
of this attack chain is to demonstrate to Inlanefreight the impact of each
vulnerability shown in this report and how they fit together to demonstrate the
overall risk to the client environment and help to prioritize remediation
efforts (i.e., patching two flaws quickly could break up the attack chain while
the company works to remediate all issues reported). While other findings shown
in this report could be leveraged to gain a similar level of access, this
attack chain shows the initial path of least resistance taken by the tester to
achieve domain compromise.

\begin{enumerate}
   \item  The tester utilized the Responder tool to obtain an NTLMv2 password hash for a domain user, bsmith.

   \item  This password hash was successfully cracked offline using the Hashcat tool to reveal the user's cleartext password, which granted a foothold into the INLANEFREIGHT.LOCAL domain, but with no more privileges than a standard domain user.

   \item  The tester then ran the BloodHound.py tool, a Python version of the popular SharpHound collection tool to enumerate the domain and create visual representations of attack paths. Upon review, the tester found that multiple privileged users existed in the domain configured with Service Principal Names (SPNs), which can be leveraged to perform a Kerberoasting attack and retrieve TGS Kerberos tickets for the accounts which can be cracked offline using Hashcat if a weak password is set. From here, the tester used the GetUserSPNs.py tool to carry out a targeted Kerberoasting attack against the mssqlsvc account, having found that the mssqlsvc account had local administrator rights over the host SQL01.INLANEFREIGHT.LOCAL which was an interesting target in the domain.

   \item  The tester successfully cracked this account's password offline, revealing the cleartext value.

   \item  The tester authenticated to the host SQL01.INLANEFREIGHT.LOCAL and retrieved a cleartext password from the host's registry by decrypting LSA secrets for an account (srvadmin), which was set up for autologon.

   \item  This srvadmin account had local administrator rights over all servers (aside from Domain Controllers) in the domain, so the tester logged into the MS01.INLANEFREIGHT.LOCAL host and retrieved a Keberos TGT ticket for a logged-in user, pramirez This user was part of the Tier I Server Admins group, which granted the account DCSync rights over the domain object. This attack can be utilized to retrieve the NTLM password hash for any user in the domain, resulting in domain compromise and persistence via a Golden Ticket.

   \item  The tester used the Rubeus tool to extract the Kerberos TGT ticket for the pramirez user and perform a Pass-the-Ticket attack to authenticate as this user.

   \item  Finally, the tester performed a DCSync attack after successfully authenticating with this user account via the Mimikatz tool, which ended in domain compromise.

\end{enumerate}

\subsubsection{Detailed reproduction steps for this attack chain are as
follows:}

Upon connecting to the network, the tester started the Responder tool and was able to capture a password hash for the bsmith user by spoofing NBT-NS/LLMNR traffic on the local network segment.
{\bf Responder}
\begin{verbatim}
jubeaz@htb[/htb]$  sudo responder -I eth0 -wrfv

                                         __
  .----.-----.-----.-----.-----.-----.--|  |.-----.----.
  |   _|  -__|__ --|  _  |  _  |     |  _  ||  -__|   _|
  |__| |_____|_____|   __|_____|__|__|_____||_____|__|
                   |__|

           NBT-NS, LLMNR & MDNS Responder 3.0.6.0

 <SNIP>

[+] Generic Options:
    Responder NIC              [eth0]
    Responder IP               [192.168.195.168]
    Challenge set              [random]
    Don't Respond To Names     ['ISATAP']

[+] Current Session Variables:
    Responder Machine Name     [WIN-TWWXTGD94CV]
    Responder Domain Name      [3BKZ.LOCAL]
    Responder DCE-RPC Port     [47032]

[+] Listening for events...

<SNIP>

[SMB] NTLMv2-SSP Client   : 192.168.195.205
[SMB] NTLMv2-SSP Username : INLANEFREIGHT\bsmith
[SMB] NTLMv2-SSP Hash     : bsmith::INLANEFREIGHT:7ecXXXXXX98ebc:73D1B2XXXXXXXXXXX45085A651:010100000000000000B588D9F766D801191BB2236A5FAAA50000000002000800330042004B005A0001001E00570049004E002D005400570057005800540047004400390034004300560004003400570049004E002D00540057005700580054004700440039003400430056002E00330042004B005A002E004CXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX2E004C004F00430041004C000700080000B588D9F766D801060004000200000008003000300000000000000001000000002000002CAE5BF3BB1FD2F846A280AEF43A8809C15207BFCB4DF5A580BA1B6FCAF6BBCE0A001000000000000000000000000000000000000900280063006900660073002F003100390032002E003100360038002E003100390035002E00310036003800000000000000000000000000

<SNIP>
\end{verbatim}

The tester was successful in "cracking" this password hash offline using the Hashcat tool and retrieving the cleartext password value, thus granting a foothold to enumerate the Active Directory domain.
{\bf Hashcat}

\ldots

\subsection{Writing a Strong Executive Summary}

The Executive Summary is one of the most important parts of the report. As
mentioned previously, our clients are ultimately paying for the report
deliverable which has several purposes aside from showing weaknesses and
reproduction steps that can be used by technical teams working on remediation.
The report will likely be viewed in some part by other internal stakeholders
such as Internal Audit, IT and IT Security management, C-level management, and
even the Board of Directors. The report may be used to either validate funding
from the prior year for infosec or to request additional funding for the
following year. For this reason, we need to ensure that there is content in the
report that can be easily understood by people without technical knowledge.

\subsubsection{Key concepts}
The intended audience for the Executive Summary is typically the person that is going to be responsible for allocating the budget to fixing the issues we discovered. For better or worse, some of our clients have likely been trying to get funding to fix the issues presented in the report for years and fully intend to use the report as ammunition to finally get some stuff done. This is our best chance to help them out. If we lose our audience here and there are budgetary limitations, the rest of the report can quickly become worthless. Some key things to assume (that may or may not be true) to maximize the effectiveness of the Executive Summary are:

\begin{itemize}
   \item  It should be obvious, but this should be written for someone who isn't technical at all. The typical barometer for this is "if your parents can't understand what the point is, then you need to try again" (assuming your parents aren't CISOs or sysadmins or something of the sort).

   \item  The reader doesn't do this every day. They don't know what Rubeus does, what password spraying means, or how it's possible that tickets can grant different tickets (or likely even what a ticket is, aside from a piece of paper to enter a concert or a ballgame).

   \item  This may be the first time they've ever been through a penetration test.

   \item  Much like the rest of the world in the instant gratification age, their attention span is small. When we lose it, we are extraordinarily unlikely to get it back.

   \item  Along the same lines, no one likes to read something where they have to Google what things mean. Those are called distractions.
\end{itemize}

\subsubsection{Do and don't}
{\bf Do}


\begin{itemize}
   \item  When talking about metrics, be as specific as possible. - Words like "several," "multiple," and "few" are ambiguous and could mean 6 or 500. Executives aren't going to dig through the report for this information, so if you're going to talk about this, let them know what you've got; otherwise, you're going to lose their attention. The most common reason people do not commit to a specific number is to leave it open in case the consultant missed one. You can make minor changes to the language to account for this, such as "while there may be additional instances of X, in the time allotted to the assessment, we observed 25 occurrences of X".

   \item  It's a summary. Keep it that way. - If you wrote more than 1.5-2 pages, you've probably been too verbose. Examine the topics you talked about and determine whether they can be collapsed into higher-level categories that might fall into specific policies or procedures.

   \item  Describe the types of things you managed to access - Your audience may not have any idea what "Domain Admin" means, but if you mention that you gained access to an account that enabled you to get your hands on HR documents, banking systems, and other critical assets, that's universally understandable.

   \item  Describe the general things that need to improve to mitigate the risks you discovered. - This should not be "install 3 patches and call me in a year". You should be thinking in terms of "what process broke down that enabled a five-year-old vulnerability to go unpatched in a quarter of the environment?". If you password spray and get 500 hits on Welcome1!, changing the passwords of those 500 accounts is only part of the solution. The other part is probably providing the Help Desk with a way to set stronger initial passwords efficiently.

   \item  If you're feeling brave and have a decent amount of experience on both sides, provide a general expectation for how much effort will be necessary to fix some of this. - If you have a long past as a sysadmin or engineer and you know how much internal politics people may have to wade through to start manipulating group policies, you may want to try and set an expectation for low, moderate, and significant levels of time and effort to correct the issues, so an overzealous CEO doesn't go tell his server team they need to apply CIS hardening templates to their GPOs over the weekend without testing them first.
\end{itemize}


{\bf Do not}
\begin{itemize}
   \item  Name or recommend specific vendors. - The deliverable is a technical document, not a sales document. It's acceptable to suggest technologies such as EDR or log aggregation but stay away from recommending specific vendors of those technologies, like CrowdStrike and Splunk. If you have experience with a particular vendor that is recent and you feel comfortable giving the client that feedback, do so out-of-band and make sure that you're clear that they should make their own decision (and probably bring the client's account executive into that discussion). If you're describing specific vulnerabilities, your reader is more likely to recognize something like "vendors like VMWare, Apache, and Adobe" instead of "vSphere, Tomcat, and Acrobat."

   \item  Use Acronyms. - IP and VPN have reached a level of ubiquity that they're maybe okay, but using acronyms for protocols and types of attacks (e.g., SNMP, MitM) is tone-deaf and will render your executive summary completely ineffective for its intended audience.

   \item  Spend more time talking about stuff that doesn't matter than you do about the significant findings in the report. - It is within your power to steer attention. Don't waste it on the issues you discovered that weren't that impactful.

   \item  Use words that no one has ever heard of before. - Having a large vocabulary is great, but if no one can understand the point you're trying to make or they have to look up what words mean, all they are is a distraction. Show that off somewhere else.

   \item  Reference a more technical section of the report. - The reason the executive is reading this might be because they don't understand the technical details, or they may decide they just don't have time for it. Also, no one likes having to scroll back and forth throughout the report to figure out what's going on.
\end{itemize}

\subsubsection{Vocabulary Changes}

To provide some examples of what it means to "write to a non-technical audience," we've provided some examples below of technical terms and acronyms you may be tempted to use, along with a less technical alternative that could be used instead. This list is not exhaustive nor the "right" way to describe these things. They are meant as examples of how you might describe a technical topic in a more universally understandable way.

\begin{itemize}
        \item VPN, SSH - a protocol used for secure remote administration
        \item SSL/TLS - technology used to facilitate secure web browsing
        \item Hash - the output from an algorithm commonly used to validate file integrity
        \item Password Spraying - an attack in which a single, easily-guessable password is attempted for a large list of harvested user accounts
        \item Password Cracking - an offline password attack in which the cryptographic form of a userâ€™s password is converted back to its human-readable form
        \item Buffer overflow/deserialization/etc. - an attack that resulted in remote command execution on the target host
        \item OSINT - Open Source Intelligence Gathering, or hunting/using data about a company and its employees that can be found using search engines and other public sources without interacting with a company's external network
        \item SQL injection/XSS - a vulnerability in which input is accepted from the user without sanitizing characters meant to manipulate the application's logic in an unintended manner
\end{itemize}
These are just a few examples. Your glossary will grow over time as you write
more reports. You can also improve this in this area by reading the executive
summaries that others have written describing some of the same findings that
you typically discover. Doing so can be the catalyst for thinking of something
in a different way. You may also receive feedback from the client from time to
time about this, and it is important to receive this feedback gracefully and
with an open mind. You may be tempted to get defensive (especially if the
client is being really aggressive), but at the end of the day, they paid you to
build them a useful product. If it isn't because they can't understand it, then
look at it as an opportunity to practice and grow. Taking client feedback as a
personal attack may be difficult not to do, but it's one of the most valuable
things they can give you.

\subsubsection{Summary of Recommendations}

Before we get into the technical findings, it's a good idea to provide a
Summary of Recommendations or Remediation Summary section. Here we can list our
short, medium, and long-term recommendations based on our findings and the
current state of the client's environment. We'll need to use our experience and
knowledge of the client's business, security budget, staffing considerations,
etc., to make accurate recommendations. Our clients will often have input on
this section, so we want to get it right, or the recommendations are useless.
If we structure this properly, our clients can use it as the basis for a
remediation roadmap. If you opt not to do this, be prepared for clients to ask
you to prioritize remediation for them. It may not happen all the time, but if
you have a report with 15 high-risk findings and nothing else, they're likely
going to want to know which of them is "the most high." As the saying goes,
"when everything is important, nothing is important."

We should tie each recommendation back to a specific finding and not include
any short or medium-term recommendations that are not actionable by remediating
findings reported later in the report. Long-term recommendations may map back
to informational/best practice recommendations such as "Create baseline
security templates for Windows Server and Workstation hosts" but may also be
catch-all recommendations such as "Perform periodic Social Engineering
engagements with follow-on debriefings and security awareness training to build
a security-focused culture within the organization from the top down."

Some findings could have an associated short and long-term recommendation. For
example, if a particular patch is missing in many places, that is a sign that
the organization struggles with patch management and perhaps does not have a
strong patch management program, along with associated policies and procedures.
The short-term solution would be to push out the relevant patches, while the
long-term objective would be to review patch and vulnerability management
processes to address any gaps that would prevent the same issue from cropping
up again. In the application security world, it might instead be fixing the
code in the short term and in the long term, reviewing the SDLC to ensure
security is considered early enough in the development process to prevent these
issues from making it into production.

\subsubsection{Findings}

After the Executive Summary, the Findings section is one of the most important.
This section gives us a chance to show off our work, paint the client a picture
of the risk to their environment, give technical teams the evidence to validate
and reproduce issues and provide remediation advice. We will discuss this
section of the report in detail in the next section of this module: How to
Write up a Finding.

\subsubsection{Appendices}

There are appendices that should appear in every report, but others will be
dynamic and may not be necessary for all reports. If any of these appendices
bloat the size of the report unnecessarily, you may want to consider whether a
supplemental spreadsheet would be a better way to present the data (not to
mention the enhanced ability to sort and filter).

\subsubsection{Static Appendices}
{\bf Scope}

Shows the scope of the assessment (URLs, network ranges, facilities, etc.).
Most auditors that the client has to hand your report to will need to see
this.

{\bf Methodology}

Explain the repeatable process you follow to ensure that your assessments are
thorough and consistent.

{\bf Severity Ratings}

If your severity ratings don't directly map to a CVSS score or something
similar, you will need to articulate the criteria necessary to meet your
severity definitions. You will have to defend this occasionally, so make sure
it is sound and can be backed up with logic and that the findings you include
in your report are rated accordingly.

{\bf Biographies}

If you perform assessments with the intent of fulfilling PCI compliance
specifically, the report should include a bio about the personnel performing
the assessment with the specific goal of articulating that the consultant is
adequately qualified to perform the assessment. Even without compliance
obligations, it can help give the client peace of mind that the person doing
their assessment knew what they were doing.

\subsubsection{Dynamic Appendices}
{\bf Exploitation Attempts and Payloads}

If you've ever done anything in incident response, you should know how many
artifacts are left behind after a penetration test for the forensics guys to
try and sift through. Be respectful and keep track of the stuff you did so that
if they experience an incident, they can differentiate what was you versus an
actual attacker. If you generate custom payloads, particularly if you drop them
on disk, you should also include the details of those payloads here, so the
client knows exactly where to go and what to look for to get rid of them. This
is especially important for payloads that you cannot clean up yourself.

{\bf Compromised Credentials}

If a large number of accounts were compromised, it is helpful to list them here
(if you compromise the entire domain, it might be a wasted effort to list out
every user account instead of just saying "all domain accounts") so that the
client can take action against them if necessary.

{\bf Configuration Changes}

If you made any configuration changes in the client environment (hopefully you
asked first), you should itemize all of them so that the client can revert them
and eliminate any risks you introduced into the environment (like disabling EDR
or something). Obviously, it's ideal if you put things back the way you found
them yourself and get approval in writing from the client to change things to
prevent getting yelled at later on if your change has unintended consequences
for a revenue-generating process.

{\bf Additional Affected Scope}

If you have a finding with a list of affected hosts that would be too much to
include with the finding itself, you can usually reference an appendix in the
finding to see a complete list of the affected hosts where you can create a
table to display them in multiple columns. This helps keep the report clean
instead of having a bulleted list several pages long.

{\bf Information Gathering}

If the assessment is an External Penetration test, we may include additional
data to help the client understand their external footprint. This could include
whois data, domain ownership information, subdomains, discovered emails,
accounts found in public breach data (DeHashed is great for this), an analysis
of the client's SSL/TLS configurations, and even a listing of externally
accessible ports/services (in a large scope external you'd likely want to make
a supplementary spreadsheet). This data can be beneficial in a
low-to-no-finding report but should convey some sort of value to the client and
not just be "fluff."

{\bf Domain Password Analysis}

If you're able to gain Domain Admin access and dump the NTDS database, it's a
good idea to run this through Hashcat with multiple wordlists and rules and
even brute-force NTLM up through eight characters if your password cracking rig
is powerful enough. Once you've exhausted your cracking attempts, a tool such
as DPAT can be used to produce a nice report with various statistics. You may
want just to include some key stats from this report (i.e., number of hashes
obtained, number and percentage cracked, number of privileged accounts cracks
(think Domain Admins and Enterprise Admins), top X passwords, and the number of
passwords cracked for each character length). This can help drive home themes
in the Executive Summary and Findings sections regarding weak passwords. You
may also wish to provide the client with the entire DPAT report as
supplementary data.